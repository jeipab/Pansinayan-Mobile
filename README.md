# Pansinayan-Mobile

**Real-time Filipino Sign Language (FSL) Recognition on Android**

**Pansinayan** translates Filipino Sign Language into text in real-time using MediaPipe keypoint extraction and optimized Transformer/GRU models. This project includes the complete Android app and model export scripts.

---

## ğŸš€ Features

- **Real-time Recognition:** 30 FPS camera feed with MediaPipe keypoint extraction
- **Continuous CTC:** Sliding window (150 frames) processes multiple signs per sequence
- **Dual Output:** Displays both **gloss** (word) and **category** for each sign
- **Dual-Model Support:** Switch between Transformer (accuracy) and GRU (speed) models
- **Skeleton Visualization:** Real-time pose and hand overlay with toggle
- **Transcript & History:** Shows last 5 signs and saves to database with CSV export

---

## âš™ï¸ System Architecture

```
Camera (30 FPS) â†’ MediaPipe (89 keypoints) â†’ Sliding Window (150 frames)
â†’ CTC Model â†’ Dual Decoder â†’ UI (Gloss + Category)
```

**How It Works:**

- **Sliding Window:** 150-frame window (5 seconds) slides forward by 10 frames every ~0.33s
- **Continuous Recognition:** Model processes overlapping windows to detect multiple signs
- **CTC Decoding:** Collapses frame-level predictions into sign sequences
- **Output:** Both gloss ("GOOD MORNING") and category ("GREETINGS") per sign

Example: Sign "GOOD MORNING EGG" â†’ Outputs: "GOOD MORNING" [GREETINGS], "EGG" [FOOD]

---

## ğŸ§© Core Components

### **1. Input Processing**

- **MediaPipeProcessor** - Extracts 89 keypoints (25 pose + 21Ã—2 hands + 22 face)
- **CameraManager** - CameraX 30 FPS capture with overlay visualization

### **2. Sequence Management**

- **SequenceBufferManager** - Maintains sliding 150-frame buffer (5 seconds)
- Slides forward by 10 frames every ~0.33s for continuous recognition

### **3. Model Inference**

- **TFLiteModelRunner** - Runs CTC models (Input: `[1, 150, 178]` â†’ Output: per-frame gloss + category)
- **CTCDecoder** - Decodes CTC outputs: collapses repeats, removes blanks, segments signs

### **4. Recognition Pipeline**

- **RecognitionPipeline** - Orchestrates sliding window inference with health monitoring
- Runs every 10 frames, processes overlapping windows, outputs gloss + category pairs

### **5. UI & Persistence**

- **MainActivity** - Live preview, transcript, model switching
- **HistoryActivity** - Recognition history with CSV export
- **AppDatabase** - Room database for storing all recognitions

---

## ğŸ“Š Model Specifications

### Input

- **Shape:** `[1, 150, 178]` (150 frames Ã— 89 keypoints Ã— 2 coordinates)
- **Type:** Float32
- **Content:** MediaPipe keypoints over 5-second sliding window

### Output

- **Gloss:** `[1, 150, 106]` - Per-frame predictions (105 signs + 1 blank)
- **Category:** `[1, 150, 10]` - Per-frame predictions (10 categories)
- **Decoded:** Both decoded independently via CTC, aligned by frame timing

### Models

- **Transformer** - High accuracy (~60-70ms inference)
- **MediaPipe-GRU** - Lightweight (~40-50ms inference)

---

## ğŸ§© Getting Started

### Prerequisites

- Android Studio + Android device/emulator (API 24+)
- Python 3.8+ with required packages (see `scripts/requirements.txt`)

---

### Step 1: Export Your Models

1. **Install dependencies:**

   ```bash
   python3 -m venv venv  # Optional, for Ubuntu
   source venv/bin/activate
   pip install -r scripts/requirements.txt
   ```

2. **Place your PyTorch checkpoints** in the project root:

   - `SignTransformerCtc_best.pt`
   - `MediaPipeGRUCtc_best.pt`

3. **Run export script:**

   ```bash
   cd scripts
   python export_ctc_models.py --model both
   ```

   Options: `--model [transformer|mediapipe_gru|both]`, `--checkpoint <path>`, `--skip-quantization`

4. **Generated files** in `models/converted/`:
   - `sign_transformer_quant.tflite` â­ (use this)
   - `sign_mediapipe_gru_quant.tflite` â­
   - `label_mapping.json`

---

### Step 2: Android Setup

1. **Open in Android Studio** - Import project from version control or extract ZIP
2. **Wait for Gradle sync** - Download dependencies (~5 minutes first time)
3. **Enable USB Debugging** (physical device):
   - Settings â†’ About Phone â†’ Tap Build Number 7x
   - Developer Options â†’ Enable USB Debugging

---

### Step 3: Copy Model Files

```bash
cp models/converted/*.tflite app/src/main/assets/
cp models/converted/label_mapping.json app/src/main/assets/
```

### Step 4: Download MediaPipe Models

Download and place in `app/src/main/assets/`:

- `hand_landmarker.task`
- `pose_landmarker_full.task`

Your `assets/` folder should contain 5 files total.

### Step 5: Build and Run

1. Verify Gradle sync complete
2. Select device from dropdown (physical device or emulator)
3. Click **Run** â–¶ï¸
4. Grant camera permission when prompted

---

## ğŸ§± Project Structure

```
.
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ main/
â”‚   â”‚   â”‚   â”œâ”€â”€ java/com/fslr/pansinayan/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ activities/        # MainActivity, HistoryActivity, HomeActivity
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ adapter/           # RecyclerView adapter for history
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ camera/            # CameraManager (CameraX setup)
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ database/          # Room database (AppDatabase, HistoryDao)
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ inference/         # TFLiteModelRunner, CTCDecoder, SequenceBufferManager
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ mediapipe/         # MediaPipeProcessor (keypoint extraction)
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ recognition/       # RecognitionPipeline
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ services/          # ScreenRecordService (video recording)
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ utils/             # LabelMapper, ModelSelector
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ views/             # OverlayView (skeleton visualization)
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ res/               # Layouts, drawables, values
â”‚   â”‚   â”‚   â””â”€â”€ assets/                # TFLite models, MediaPipe tasks, label mappings
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ build.gradle
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ export_ctc_models.py           # Python script to export CTC models
â”‚   â””â”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ’¡ Credits

Developed as part of the **Pansinayan Project**, dedicated to improving accessibility and communication for the Filipino Deaf community.
